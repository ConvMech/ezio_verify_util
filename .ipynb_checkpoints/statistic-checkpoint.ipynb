{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('class good total: ', 415)\n",
      "('class bad total: ', 116)\n",
      "((531, 18), (531,), 531)\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "json_dir='/Users/tommy/workspace/data/psout/ezio_checker.json'\n",
    "\n",
    "class confmat_stat(object):\n",
    "    def __init__(self,path):\n",
    "        try:\n",
    "            with open(path, 'rb')  as f:\n",
    "                self.data = json.load(f)\n",
    "                #print \"read data complete\"\n",
    "                self.enable = True\n",
    "        except Exception as e:\n",
    "                print e\n",
    "        self.order = self.data.keys()\n",
    "        self.class_good = []\n",
    "        self.class_bad = []\n",
    "        \n",
    "    def category(self):\n",
    "        for orderId in self.order:\n",
    "            viewList = self.data[orderId].keys()\n",
    "            for viewId in viewList:\n",
    "                one_view = self.data[orderId][viewId]\n",
    "                if (one_view['label'] == 'good'):\n",
    "                    self.class_good.append((one_view,(orderId,viewId)))\n",
    "                elif (one_view['label'] == 'bad'):\n",
    "                    self.class_bad.append((one_view,(orderId,viewId)))\n",
    "        print('class good total: ',len(self.class_good))\n",
    "        print('class bad total: ',len(self.class_bad))\n",
    "        \n",
    "    def flatten_data(self,one_view):\n",
    "        #print(one_view.keys())\n",
    "        recall_vec = np.array(one_view['recall']).flatten()\n",
    "        iou_vec = np.array(one_view['iou']).flatten()\n",
    "        confmat = np.array(one_view['matrix']).flatten()\n",
    "        prec_vec = np.array(one_view['precision']).flatten()\n",
    "        \n",
    "        feature_vec = np.array([])\n",
    "        feature_vec = np.hstack((feature_vec,confmat))\n",
    "        feature_vec = np.hstack((feature_vec,prec_vec))\n",
    "        feature_vec = np.hstack((feature_vec,recall_vec))\n",
    "        feature_vec = np.hstack((feature_vec,iou_vec))\n",
    "        \n",
    "        return feature_vec\n",
    "    \n",
    "    def concat(self):\n",
    "        data = np.array([])\n",
    "        label = []\n",
    "        id_list = []\n",
    "        dim = 0\n",
    "        for class_good_, id_tuple in self.class_good:\n",
    "            data = np.hstack((data,self.flatten_data(class_good_)))\n",
    "            dim = len(self.flatten_data(class_good_))\n",
    "            label.append(1)\n",
    "            id_list.append(id_tuple)\n",
    "        for class_bad_, id_tuple in self.class_bad:\n",
    "            data = np.hstack((data,self.flatten_data(class_bad_)))\n",
    "            label.append(2)\n",
    "            id_list.append(id_tuple)\n",
    "        #print(dim)\n",
    "        data = np.reshape(data, (-1,dim))\n",
    "        label = np.array(label)\n",
    "        self.id_list = id_list\n",
    "        return data,label,id_list\n",
    "    \n",
    "    def get_label(self,id_tuple):\n",
    "        orderId,viewId = id_tuple\n",
    "        one_view = self.data[orderId][viewId]\n",
    "        return one_view['label']\n",
    "    \n",
    "stat = confmat_stat(json_dir)\n",
    "stat.category()\n",
    "data,label,id_list = stat.concat()\n",
    "print(data.shape,label.shape,len(id_list))\n",
    "print(stat.get_label(id_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((531, 18), (531,))\n",
      "('test acc', 0.8568738229755178)\n",
      "('coef', array([[ 1.06672942e-04, -1.59543073e-03,  2.04709466e-04,\n",
      "         3.34274845e-03,  7.10280479e-05,  1.74612024e-03,\n",
      "         3.71186253e-03, -8.92309024e-04,  1.05302839e-04,\n",
      "         2.54929044e+01, -1.55655138e+01, -6.48062639e-01,\n",
      "        -3.83726770e+01,  6.49433616e+01, -8.06837243e-01,\n",
      "         1.03610580e+01, -3.21869585e+01,  1.54801054e+00]]))\n",
      "('interc', array([-23.79531863]))\n",
      "('scaling', array([[ 5.25041505e-05, -7.85266948e-04,  1.00757478e-04,\n",
      "         1.64529228e-03,  3.49598244e-05,  8.59435939e-04,\n",
      "         1.82696929e-03, -4.39192231e-04,  5.18297895e-05,\n",
      "         1.25475427e+01, -7.66130630e+00, -3.18974782e-01,\n",
      "        -1.88869340e+01,  3.19649573e+01, -3.97123238e-01,\n",
      "         5.09968640e+00, -1.58423391e+01,  7.61926849e-01]]))\n",
      "[2.74060000e+04 7.20000000e+01 2.50000000e+01 9.99000000e+02\n",
      " 2.04270000e+04 1.63000000e+02 2.00000000e+01 8.20000000e+01\n",
      " 9.82000000e+02 9.64151275e-01 9.92517370e-01 8.39316239e-01\n",
      " 9.96473112e-01 9.46176293e-01 9.05904059e-01 9.60872309e-01\n",
      " 9.39474773e-01 7.72012579e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = data\n",
    "y = label\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "clf = LinearDiscriminantAnalysis(store_covariance=False,n_components=1)\n",
    "clf.fit(X, y)\n",
    "print(\"test acc\",clf.score(X,y))\n",
    "\n",
    "print(\"coef\",clf.coef_)\n",
    "print(\"interc\",clf.intercept_)\n",
    "print(\"scaling\",clf.scalings_.T)\n",
    "\n",
    "scaling = clf.scalings_.T\n",
    "coef = np.array(clf.coef_)\n",
    "inter = clf.intercept_\n",
    "\n",
    "print(data[0])\n",
    "\n",
    "for idx,test_data in enumerate(data):\n",
    "    test_data = np.asmatrix(test_data)\n",
    "\n",
    "    inference = np.dot(test_data,coef.T) + inter\n",
    "    inference_prob = np.reciprocal(np.exp(-inference) + 1)\n",
    "    \n",
    "    raw_prediction = clf.predict(test_data)\n",
    "\n",
    "    if(raw_prediction == 2):\n",
    "        prediction = 'bad'\n",
    "    elif (raw_prediction == 1):\n",
    "        prediction = 'good'\n",
    "    ground_truth = stat.get_label(id_list[idx])\n",
    "    if(prediction != ground_truth):\n",
    "        pass\n",
    "        #print(\"class pred\",prediction,\"ground truth\",ground_truth)\n",
    "        \n",
    "        #print(clf.predict_proba(test_data))\n",
    "        \n",
    "        #print(\"ID\",id_list[idx])\n",
    "        \n",
    "    #print(\"transform\",clf.decision_function(test_data))\n",
    "#print(clf.covariance_)\n",
    "#print(clf.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8079470198675497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommy/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X, y)\n",
    "print(qda.score(X,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
