{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('class good total: ', 74)\n",
      "('class bad total: ', 77)\n",
      "((151, 18), (151,), 151)\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "json_dir='/Users/tommy/workspace/data/psout/ezio_checker.json'\n",
    "\n",
    "class confmat_stat(object):\n",
    "    def __init__(self,path):\n",
    "        try:\n",
    "            with open(path, 'rb')  as f:\n",
    "                self.data = json.load(f)\n",
    "                #print \"read data complete\"\n",
    "                self.enable = True\n",
    "        except Exception as e:\n",
    "                print e\n",
    "        self.order = self.data.keys()\n",
    "        self.class_good = []\n",
    "        self.class_bad = []\n",
    "        \n",
    "    def category(self):\n",
    "        for orderId in self.order:\n",
    "            viewList = self.data[orderId].keys()\n",
    "            for viewId in viewList:\n",
    "                one_view = self.data[orderId][viewId]\n",
    "                if (one_view['label'] == 'good'):\n",
    "                    self.class_good.append((one_view,(orderId,viewId)))\n",
    "                elif (one_view['label'] == 'bad'):\n",
    "                    self.class_bad.append((one_view,(orderId,viewId)))\n",
    "        print('class good total: ',len(self.class_good))\n",
    "        print('class bad total: ',len(self.class_bad))\n",
    "        \n",
    "    def flatten_data(self,one_view):\n",
    "        #print(one_view.keys())\n",
    "        recall_vec = np.array(one_view['recall']).flatten()\n",
    "        iou_vec = np.array(one_view['iou']).flatten()\n",
    "        confmat = np.array(one_view['matrix']).flatten()\n",
    "        prec_vec = np.array(one_view['precision']).flatten()\n",
    "        \n",
    "        feature_vec = np.array([])\n",
    "        feature_vec = np.hstack((feature_vec,confmat))\n",
    "        feature_vec = np.hstack((feature_vec,prec_vec))\n",
    "        feature_vec = np.hstack((feature_vec,recall_vec))\n",
    "        feature_vec = np.hstack((feature_vec,iou_vec))\n",
    "        \n",
    "        return feature_vec\n",
    "    \n",
    "    def concat(self):\n",
    "        data = np.array([])\n",
    "        label = []\n",
    "        id_list = []\n",
    "        dim = 0\n",
    "        for class_good_, id_tuple in self.class_good:\n",
    "            data = np.hstack((data,self.flatten_data(class_good_)))\n",
    "            dim = len(self.flatten_data(class_good_))\n",
    "            label.append(1)\n",
    "            id_list.append(id_tuple)\n",
    "        for class_bad_, id_tuple in self.class_bad:\n",
    "            data = np.hstack((data,self.flatten_data(class_bad_)))\n",
    "            label.append(2)\n",
    "            id_list.append(id_tuple)\n",
    "        #print(dim)\n",
    "        data = np.reshape(data, (-1,dim))\n",
    "        label = np.array(label)\n",
    "        self.id_list = id_list\n",
    "        return data,label,id_list\n",
    "    \n",
    "    def get_label(self,id_tuple):\n",
    "        orderId,viewId = id_tuple\n",
    "        one_view = self.data[orderId][viewId]\n",
    "        return one_view['label']\n",
    "    \n",
    "stat = confmat_stat(json_dir)\n",
    "stat.category()\n",
    "data,label,id_list = stat.concat()\n",
    "print(data.shape,label.shape,len(id_list))\n",
    "print(stat.get_label(id_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((151, 18), (151,))\n",
      "('test acc', 0.8145695364238411)\n",
      "('coef', array([[ 1.91421674e-04, -1.43421627e-03,  4.60424363e-05,\n",
      "         1.04678782e-03,  9.96335743e-05,  1.00164328e-03,\n",
      "         4.08150387e-03, -8.88615918e-04, -2.49910258e-04,\n",
      "         2.90427129e+01, -1.66012712e+01, -2.05925450e+00,\n",
      "        -3.62422893e+00,  2.70976973e+01, -2.35328940e+00,\n",
      "        -2.97229115e+01, -1.47014008e+01,  3.36642418e+00]]))\n",
      "('interc', array([-0.67758561]))\n",
      "('scaling', array([[ 1.13885171e-04, -8.53278326e-04,  2.73926699e-05,\n",
      "         6.22780100e-04,  5.92763944e-05,  5.95921633e-04,\n",
      "         2.42826612e-03, -5.28676683e-04, -1.48682601e-04,\n",
      "         1.72787869e+01, -9.87682621e+00, -1.22514105e+00,\n",
      "        -2.15621315e+00,  1.61216116e+01, -1.40007534e+00,\n",
      "        -1.76834670e+01, -8.74650980e+00,  2.00283377e+00]]))\n",
      "[2.04540000e+04 7.47300000e+03 0.00000000e+00 3.44600000e+03\n",
      " 1.87660000e+04 4.00000000e+00 1.00000000e+00 3.20000000e+01\n",
      " 0.00000000e+00 8.55780093e-01 7.14323779e-01 1.00000000e+00\n",
      " 7.32409496e-01 8.44706518e-01 1.00000000e+00 6.51941098e-01\n",
      " 6.31405404e-01 1.00000000e+00]\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.18229352 0.81770648]]\n",
      "('ID', (u'723998', u'6526312'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.42563141 0.57436859]]\n",
      "('ID', (u'764934', u'6907678'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.39502233 0.60497767]]\n",
      "('ID', (u'768122', u'6937326'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.34837987 0.65162013]]\n",
      "('ID', (u'762780', u'6887104'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.19546185 0.80453815]]\n",
      "('ID', (u'762370', u'6883326'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.10159319 0.89840681]]\n",
      "('ID', (u'765817', u'6915775'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.18463417 0.81536583]]\n",
      "('ID', (u'765719', u'6914867'))\n",
      "('class pred', 'bad', 'ground truth', u'good')\n",
      "[[0.14467066 0.85532934]]\n",
      "('ID', (u'760027', u'6861451'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.53192504 0.46807496]]\n",
      "('ID', (u'760267', u'6863594'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.57422483 0.42577517]]\n",
      "('ID', (u'760267', u'6863597'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.56292019 0.43707981]]\n",
      "('ID', (u'767050', u'6927636'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.78659216 0.21340784]]\n",
      "('ID', (u'761723', u'6877152'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.64351203 0.35648797]]\n",
      "('ID', (u'764934', u'6907677'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.71630341 0.28369659]]\n",
      "('ID', (u'762811', u'6887415'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.85616087 0.14383913]]\n",
      "('ID', (u'762780', u'6887107'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.82849478 0.17150522]]\n",
      "('ID', (u'764591', u'6904522'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.9118152 0.0881848]]\n",
      "('ID', (u'766488', u'6922163'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.77539194 0.22460806]]\n",
      "('ID', (u'762370', u'6883332'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.52362793 0.47637207]]\n",
      "('ID', (u'766687', u'6924152'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.53415678 0.46584322]]\n",
      "('ID', (u'760724', u'6867722'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.75816938 0.24183062]]\n",
      "('ID', (u'764888', u'6907215'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.86712476 0.13287524]]\n",
      "('ID', (u'766108', u'6918597'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.51375527 0.48624473]]\n",
      "('ID', (u'764420', u'6902931'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.57207875 0.42792125]]\n",
      "('ID', (u'765117', u'6909348'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.66363625 0.33636375]]\n",
      "('ID', (u'765719', u'6914869'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.60600383 0.39399617]]\n",
      "('ID', (u'768436', u'6940299'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.85111691 0.14888309]]\n",
      "('ID', (u'768436', u'6940296'))\n",
      "('class pred', 'good', 'ground truth', u'bad')\n",
      "[[0.72341324 0.27658676]]\n",
      "('ID', (u'764701', u'6905530'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = data\n",
    "y = label\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "clf = LinearDiscriminantAnalysis(store_covariance=False,n_components=1)\n",
    "clf.fit(X, y)\n",
    "print(\"test acc\",clf.score(X,y))\n",
    "\n",
    "print(\"coef\",clf.coef_)\n",
    "print(\"interc\",clf.intercept_)\n",
    "print(\"scaling\",clf.scalings_.T)\n",
    "\n",
    "scaling = clf.scalings_.T\n",
    "coef = np.array(clf.coef_)\n",
    "inter = clf.intercept_\n",
    "\n",
    "print(data[0])\n",
    "\n",
    "for idx,test_data in enumerate(data):\n",
    "    test_data = np.asmatrix(test_data)\n",
    "\n",
    "    inference = np.dot(test_data,coef.T) + inter\n",
    "    inference_prob = np.reciprocal(np.exp(-inference) + 1)\n",
    "    \n",
    "    raw_prediction = clf.predict(test_data)\n",
    "\n",
    "    if(raw_prediction == 2):\n",
    "        prediction = 'bad'\n",
    "    elif (raw_prediction == 1):\n",
    "        prediction = 'good'\n",
    "    ground_truth = stat.get_label(id_list[idx])\n",
    "    if(prediction != ground_truth):\n",
    "        print(\"class pred\",prediction,\"ground truth\",ground_truth)\n",
    "        \n",
    "        print(clf.predict_proba(test_data))\n",
    "        \n",
    "        print(\"ID\",id_list[idx])\n",
    "        \n",
    "    #print(\"transform\",clf.decision_function(test_data))\n",
    "#print(clf.covariance_)\n",
    "#print(clf.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8079470198675497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommy/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X, y)\n",
    "print(qda.score(X,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
